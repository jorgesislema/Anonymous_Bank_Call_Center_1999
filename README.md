# ğŸ¦ AnÃ¡lisis Integral del Call Center - Anonymous Bank

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto realiza un anÃ¡lisis exhaustivo de los datos del call center del "Anonymous Bank" correspondientes al aÃ±o 1999. Implementamos un pipeline completo de ETL (Extract, Transform, Load), EDA (Exploratory Data Analysis) y modelado predictivo para optimizar las operaciones del call center.

## ğŸ¯ Objetivos del Proyecto

### Objetivos Principales
- **AnÃ¡lisis Operacional**: Identificar patrones en volumen de llamadas, tiempos de espera y eficiencia del servicio
- **OptimizaciÃ³n de Recursos**: Determinar la distribuciÃ³n Ã³ptima de agentes por horarios y dÃ­as
- **PredicciÃ³n de Demanda**: Desarrollar modelos para predecir picos de llamadas
- **AnÃ¡lisis de SatisfacciÃ³n**: Evaluar tasas de abandono y factores que las influencian
- **SegmentaciÃ³n de Clientes**: Clasificar clientes segÃºn patrones de uso y prioridad

### Objetivos Secundarios
- **Dashboard Interactivo**: Crear visualizaciones en Power BI para monitoreo en tiempo real
- **AutomatizaciÃ³n ETL**: Desarrollar pipeline automatizado para procesamiento de datos
- **Modelos Predictivos**: Implementar ML para forecasting y clasificaciÃ³n
- **Recomendaciones EstratÃ©gicas**: Proponer mejoras operacionales basadas en datos

## ğŸ—ï¸ Arquitectura del Proyecto

```
call_center_analysis/
â”œâ”€â”€ 00_data/                    # Datos del proyecto
â”‚   â”œâ”€â”€ raw/                    # Datos originales sin procesar
â”‚   â”‚   â””â”€â”€ Call_Center_1999_DataSet.csv
â”‚   â”œâ”€â”€ processed/              # Datos limpios y transformados
â”‚   â”‚   â”œâ”€â”€ clean_call_data.csv
â”‚   â”‚   â”œâ”€â”€ aggregated_metrics.csv
â”‚   â”‚   â””â”€â”€ featured_dataset.csv
â”‚   â””â”€â”€ external/               # Datos externos y maestros
â”‚       â”œâ”€â”€ holidays_israel_1999.csv
â”‚       â”œâ”€â”€ agent_shifts.csv
â”‚       â””â”€â”€ customer_segments.csv
â”‚
â”œâ”€â”€ 01_notebooks/               # Jupyter Notebooks para anÃ¡lisis
â”‚   â”œâ”€â”€ sandbox/                # Experimentos y pruebas
â”‚   â”œâ”€â”€ 01_initial_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning_transformation.ipynb
â”‚   â”œâ”€â”€ 03_exploratory_data_analysis.ipynb
â”‚   â”œâ”€â”€ 04_statistical_analysis.ipynb
â”‚   â”œâ”€â”€ 05_machine_learning_models.ipynb
â”‚   â””â”€â”€ 06_final_insights_recommendations.ipynb
â”‚
â”œâ”€â”€ 02_src/                     # CÃ³digo fuente modularizado
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_ingestion.py       # Funciones para cargar datos
â”‚   â”œâ”€â”€ data_cleaning.py        # Limpieza y validaciÃ³n
â”‚   â”œâ”€â”€ feature_engineering.py  # CreaciÃ³n de variables
â”‚   â”œâ”€â”€ analysis.py             # Funciones de anÃ¡lisis
â”‚   â”œâ”€â”€ modeling.py             # Modelos de ML
â”‚   â”œâ”€â”€ visualization.py        # GrÃ¡ficos y visualizaciones
â”‚   â””â”€â”€ utils.py                # Utilidades generales
â”‚
â”œâ”€â”€ 03_dashboards/              # Dashboards y aplicaciones
â”‚   â”œâ”€â”€ power_bi/
â”‚   â”‚   â”œâ”€â”€ call_center_dashboard.pbix
â”‚   â”‚   â””â”€â”€ data_model.json
â”‚   â”œâ”€â”€ streamlit/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ components/
â”‚   â””â”€â”€ dash/
â”‚       â””â”€â”€ interactive_dashboard.py
â”‚
â”œâ”€â”€ 04_reports/                 # Reportes y documentaciÃ³n
â”‚   â”œâ”€â”€ figures/                # GrÃ¡ficos y visualizaciones
â”‚   â”œâ”€â”€ executive_summary.pdf
â”‚   â”œâ”€â”€ technical_report.md
â”‚   â””â”€â”€ presentation.pptx
â”‚
â”œâ”€â”€ tests/                      # Tests unitarios
â”‚   â”œâ”€â”€ test_data_cleaning.py
â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ config/                     # Configuraciones
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ logging_config.py
â”‚
â”œâ”€â”€ requirements.txt            # Dependencias de Python
â”œâ”€â”€ setup.py                   # ConfiguraciÃ³n del paquete
â”œâ”€â”€ .env.template              # Variables de entorno
â”œâ”€â”€ .gitignore                 # Archivos a ignorar en git
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ“Š DescripciÃ³n del Dataset

### InformaciÃ³n General
- **PerÃ­odo**: 1 de enero de 1999 - 31 de diciembre de 1999
- **Volumen**: ~20,000-30,000 llamadas por mes
- **Registros**: Cada fila representa una llamada individual
- **Campos**: 17 columnas con informaciÃ³n detallada de cada llamada

### Estructura de Datos

| Campo | DescripciÃ³n | Tipo | Valores Posibles |
|-------|-------------|------|------------------|
| `vru+line` | ID del VRU y lÃ­nea (AA01-AA06, lÃ­neas 1-16) | String | AA01-1 a AA06-16 |
| `call_id` | Identificador Ãºnico de llamada | Integer | 5 dÃ­gitos |
| `customer_id` | ID del cliente (0 si no identificado) | Integer | 0-12 dÃ­gitos |
| `priority` | Prioridad del cliente | Integer | 0=Regular, 1=Regular, 2=Alta |
| `type` | Tipo de servicio | String | PS, PE, IN, NE, NW, TT |
| `date` | Fecha de la llamada | Date | YYMMDD |
| `vru_entry` | Hora de entrada al VRU | Time | HHMMSS |
| `vru_exit` | Hora de salida del VRU | Time | HHMMSS |
| `vru_time` | Tiempo en VRU (segundos) | Integer | 1-999 |
| `q_start` | Hora de entrada a cola | Time | HHMMSS |
| `q_exit` | Hora de salida de cola | Time | HHMMSS |
| `q_time` | Tiempo en cola (segundos) | Integer | 1-999 |
| `outcome` | Resultado de la llamada | String | AGENT, HANG, PHANTOM |
| `ser_start` | Inicio del servicio | Time | HHMMSS |
| `ser_exit` | Fin del servicio | Time | HHMMSS |
| `ser_time` | DuraciÃ³n del servicio (segundos) | Integer | 1-999 |
| `server` | Agente que atendiÃ³ | String | Nombre o NO_SERVER |

### Tipos de Servicio
- **PS**: Actividad Regular
- **PE**: Actividad Regular en InglÃ©s
- **IN**: Consulta por Internet/Home Banking
- **NE**: Actividad por Acciones (Bolsa)
- **NW**: Cliente Prospecto
- **TT**: Callback solicitado por cliente

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Python 3.8+
- Git
- Power BI Desktop (para dashboards)
- Jupyter Notebook/Lab

### InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd call_center_analysis
```

2. **Crear entorno virtual**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
cp .env.template .env
# Editar .env con tus configuraciones
```

5. **Ejecutar tests**
```bash
pytest tests/
```

## ğŸ“ˆ MetodologÃ­a de AnÃ¡lisis

### Fase 1: ETL (Extract, Transform, Load)
1. **ExtracciÃ³n**: Carga de datos desde CSV
2. **TransformaciÃ³n**: 
   - Limpieza de datos faltantes y outliers
   - ConversiÃ³n de tipos de datos
   - CreaciÃ³n de variables derivadas
3. **Carga**: Almacenamiento en formatos optimizados

### Fase 2: EDA (Exploratory Data Analysis)
1. **AnÃ¡lisis Descriptivo**: EstadÃ­sticas bÃ¡sicas y distribuciones
2. **AnÃ¡lisis Temporal**: Patrones por hora, dÃ­a, mes
3. **AnÃ¡lisis de Servicios**: Performance por tipo de servicio
4. **AnÃ¡lisis de Agentes**: Eficiencia y carga de trabajo

### Fase 3: AnÃ¡lisis Avanzado
1. **AnÃ¡lisis EstadÃ­stico**: Tests de hipÃ³tesis y correlaciones
2. **SegmentaciÃ³n**: Clustering de clientes y llamadas
3. **Modelado Predictivo**: Forecasting y clasificaciÃ³n
4. **OptimizaciÃ³n**: SimulaciÃ³n de escenarios

## ğŸ› ï¸ Herramientas y TecnologÃ­as

### AnÃ¡lisis de Datos
- **Python**: Lenguaje principal
- **Pandas**: ManipulaciÃ³n de datos
- **NumPy**: CÃ¡lculos numÃ©ricos
- **SciPy**: AnÃ¡lisis estadÃ­stico

### VisualizaciÃ³n
- **Matplotlib/Seaborn**: GrÃ¡ficos estÃ¡ticos
- **Plotly**: Visualizaciones interactivas
- **Power BI**: Dashboard ejecutivo
- **Streamlit/Dash**: Aplicaciones web

### Machine Learning
- **Scikit-learn**: Modelos tradicionales
- **XGBoost/LightGBM**: Boosting algorithms
- **Statsmodels**: AnÃ¡lisis estadÃ­stico avanzado

## ğŸ“Š AnÃ¡lisis Propuestos

### 1. AnÃ¡lisis Operacional
- DistribuciÃ³n de llamadas por hora/dÃ­a/mes
- Tiempos promedio de espera y servicio
- Tasas de abandono por perÃ­odo
- Eficiencia por agente y VRU

### 2. AnÃ¡lisis de Clientes
- SegmentaciÃ³n por comportamiento
- AnÃ¡lisis de clientes de alta prioridad
- Patrones de uso por tipo de servicio
- Customer Journey mapping

### 3. AnÃ¡lisis Predictivo
- Forecasting de volumen de llamadas
- PredicciÃ³n de tasas de abandono
- OptimizaciÃ³n de staffing
- DetecciÃ³n de anomalÃ­as

### 4. AnÃ¡lisis de Calidad
- Service Level Agreements (SLA)
- Factores que afectan satisfacciÃ³n
- ComparaciÃ³n de performance entre agentes
- IdentificaciÃ³n de mejores prÃ¡cticas

## ğŸ¯ KPIs y MÃ©tricas Clave

### MÃ©tricas Operacionales
- **Average Handle Time (AHT)**: Tiempo promedio de manejo
- **First Call Resolution (FCR)**: ResoluciÃ³n en primera llamada
- **Service Level**: % llamadas atendidas en tiempo objetivo
- **Abandonment Rate**: Tasa de abandono

### MÃ©tricas de Eficiencia
- **Agent Utilization**: UtilizaciÃ³n de agentes
- **Queue Time**: Tiempo promedio en cola
- **VRU Efficiency**: Eficiencia del sistema VRU
- **Peak Hour Analysis**: AnÃ¡lisis de horas pico

### MÃ©tricas de Calidad
- **Customer Satisfaction**: SatisfacciÃ³n del cliente
- **Call Quality Score**: PuntuaciÃ³n de calidad
- **Repeat Call Rate**: Tasa de llamadas repetidas
- **Agent Performance**: Performance por agente

## ğŸ“‹ Fuentes de Datos Adicionales Requeridas

### Datos Internos Necesarios
1. **Maestro de Agentes**
   - ID, nombre, turno, habilidades
   - Fecha de ingreso, capacitaciÃ³n
   - Performance histÃ³rico

2. **Calendario de Feriados**
   - Feriados nacionales en Israel 1999
   - DÃ­as especiales bancarios
   - Horarios especiales

3. **InformaciÃ³n de Clientes**
   - DemografÃ­a, segmento, antigÃ¼edad
   - Productos contratados
   - Historial de transacciones

### Datos Externos Sugeridos
1. **Datos EconÃ³micos**
   - Indicadores econÃ³micos de Israel 1999
   - Eventos del mercado financiero
   - Noticias relevantes del sector bancario

2. **Datos de Competencia**
   - Benchmarks de la industria
   - EstÃ¡ndares de servicio
   - Mejores prÃ¡cticas del sector

## ğŸš€ Pasos para Ejecutar el AnÃ¡lisis

### 1. PreparaciÃ³n Inicial
```bash
# Activar entorno y instalar dependencias
pip install -r requirements.txt

# Ejecutar notebook inicial
jupyter notebook 01_notebooks/01_initial_data_exploration.ipynb
```

### 2. Pipeline ETL
```bash
# Ejecutar limpieza de datos
python 02_src/data_cleaning.py

# Ejecutar feature engineering
python 02_src/feature_engineering.py
```

### 3. AnÃ¡lisis Exploratorio
```bash
# Ejecutar anÃ¡lisis completo
jupyter notebook 01_notebooks/03_exploratory_data_analysis.ipynb
```

### 4. Dashboard
```bash
# Ejecutar dashboard Streamlit
streamlit run 03_dashboards/streamlit/app.py
```

## ğŸ‘¥ Equipo y Contribuidores

### Roles Sugeridos
- **Data Scientist**: AnÃ¡lisis y modelado
- **Data Engineer**: Pipeline ETL
- **Business Analyst**: InterpretaciÃ³n de resultados
- **Visualization Specialist**: Dashboards y reportes

## ğŸ“ Contacto y Soporte

Para preguntas o sugerencias sobre este proyecto:
- ğŸ“§ Email: [tu-email@empresa.com]
- ğŸ’¬ Slack: #call-center-analysis
- ğŸ“š Wiki: [Link a documentaciÃ³n interna]

## ğŸ“„ Licencia

Este proyecto es propiedad de [Tu Empresa] y estÃ¡ sujeto a las polÃ­ticas internas de uso de datos.

---

**Ãšltima actualizaciÃ³n**: Mayo 2025
**VersiÃ³n**: 1.0.0
**Estado**: En desarrollo activoCall_Center
Caso de negocio basado en un Call Center de un Banco: â€œAnonymous Bankâ€ en Israel. El dataset contiene las llamadas registradas durante 12 meses (desde el 01/01/99 hasta el 31/12/99)
